# Introduction

This project provides sample recipes for serving generative AI models using BentoML - an open-source framework for serving, managing, and deploying machine learning models.

## What is BentoML?

BentoML simplifies the deployment of machine learning models into production. It offers a standardized way to package models with their dependencies, making them easy to deploy as microservices.

## What's Included

This repository contains examples and templates demonstrating how to:

- Deploy various generative AI models (text, image, multimodal)
- Optimize serving performance for large models
- Configure APIs for model interaction
- Scale deployments based on demand

## Use Cases

These recipes are particularly useful for:
- ML engineers looking to productionize generative AI models
- Data scientists exploring deployment options
- DevOps professionals integrating AI into existing infrastructure

## Getting Started

Check out the individual examples in this repository to learn how to adapt these recipes to your specific models and use cases.
